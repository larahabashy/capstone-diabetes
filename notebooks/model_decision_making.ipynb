{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80babc7f",
   "metadata": {},
   "source": [
    "## Deciding on a Model Using Manual Analysis with Gradio\n",
    "\n",
    "This notebook documents some of the steps taken to choose the final model for deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e749469",
   "metadata": {},
   "source": [
    "For this project, we played around with four different models to see which performed best for our dataset. Our initial literature search showcased four different models that are popular for transfer learning including:\n",
    "\n",
    "1. Densenet\n",
    "2. Resnet\n",
    "3. Vgg16\n",
    "4. Inception\n",
    "\n",
    "After conducting extensive runs to choose the [best image transformations](https://github.com/UBC-MDS/capstone-gdrl-lipo/blob/master/notebooks/manual-albumentation.ipynb) and doing hyperparameter tuning on the individual [models](https://github.com/UBC-MDS/capstone-gdrl-lipo/tree/master/notebooks), we used these optimized models to do a manual analysis of images to compare the models. We build a [local internal decision making tool app using gradio](https://github.com/UBC-MDS/capstone-gdrl-lipo/tree/master/notebooks/gradio_demo.ipynb) to analyze specific test cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76f690",
   "metadata": {},
   "source": [
    "## Reviewing Specific Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc0969",
   "metadata": {},
   "source": [
    "Below are some screenshots from the gradio app of some negative and positive images that the model has never seen. Six negative images and five positives images were chosen for a manual review in hopes to pick out ways to see how the model would do on examples that are visually hard for the human eye to identify and label correctly. All models were able to catch negative examples relatively well. Densenet stood out was able to capture 4 out of the 6 images well compared to the rest of the models with very high confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191624ee",
   "metadata": {},
   "source": [
    "### Negative Image Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d85d44",
   "metadata": {},
   "source": [
    "We chose a difficult negative image example that features a circular ball that to the eye appears to be lipohypertrophy but it is not. We can see that although all models predict negative, Densenet is the most confident in its prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb10e3d",
   "metadata": {},
   "source": [
    "![true_neg_densenet_right](../image/true_neg_densenet_right.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15da84b",
   "metadata": {},
   "source": [
    "## Positive Image Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c2d62",
   "metadata": {},
   "source": [
    "Identifying positives was hard for all models and the below figure shows an example where all model struggled. It makes sense that all the models are struggling as we don't have a very large dataset (~300 total images with a 62:38 split for negative:positive) and it's hard to tell visually where the lipohypertrophy is present or not. However, we noticed that even when Densenet is wrong, it is less confident in its prediction. This is ideal as our capstone partner has identified that the model should be less confident in its prediction when its wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39c06e",
   "metadata": {},
   "source": [
    "![true_pos_all_wrong](../image/true_pos_all_wrong.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f8129",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fbc65a",
   "metadata": {},
   "source": [
    "From this manual visualization excercise, we were able to narrow down our model choice to Densenet. According to the recall and accuracy, this model has the highest score, so even when it is wrong, it is not as confident in its prediction. Lastly, due to resource limitation on the deployment of this application, DenseNet is also the smallest app. So, the next steps were to optimize the Densenet model to further improve the scores. Two steps taken were:\n",
    "\n",
    "1. Increase the pos_weight argument of the optimizer so that there is a greater loss on positive examples\n",
    "2. Play around with the dropout rate in the model architechture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lipoenv]",
   "language": "python",
   "name": "conda-env-lipoenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
